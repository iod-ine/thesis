<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>1&nbsp; Introduction – A deep learning framework for mixed dense forests parameter estimation at individual tree scale</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/02_literature_review.html" rel="next">
<link href="../index.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/01_introduction.html"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Tree-scale parameter estimation with deep learning</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/iod-ine/thesis" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="../ivan-dubrovin-phd-thesis.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Acknowledgments <span style="visibility: hidden">🌹</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/01_introduction.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/02_literature_review.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Literature review</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/03_materials_and_methods.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Materials and methods</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/04_results.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Results</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/05_conclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Conclusion</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/99_references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#context" id="toc-context" class="nav-link active" data-scroll-target="#context"><span class="header-section-number">1.1</span> Context</a></li>
  <li><a href="#research-question-and-hypothesis" id="toc-research-question-and-hypothesis" class="nav-link" data-scroll-target="#research-question-and-hypothesis"><span class="header-section-number">1.2</span> Research question and hypothesis</a></li>
  <li><a href="#overview-of-the-framework" id="toc-overview-of-the-framework" class="nav-link" data-scroll-target="#overview-of-the-framework"><span class="header-section-number">1.3</span> Overview of the framework</a></li>
  <li><a href="#thesis-structure" id="toc-thesis-structure" class="nav-link" data-scroll-target="#thesis-structure"><span class="header-section-number">1.4</span> Thesis structure</a></li>
  <li><a href="#data-and-code-availability" id="toc-data-and-code-availability" class="nav-link" data-scroll-target="#data-and-code-availability"><span class="header-section-number">1.5</span> Data and code availability</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/iod-ine/thesis/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li><li><a href="https://github.com/iod-ine/thesis/blob/main/chapters/01_introduction.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-introduction" class="quarto-section-identifier"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>This chapter aims to give a general introduction to the research project and put it into wide scientific and societal context. It defines the main research question and the hypothesis, and gives a high-level overview of the proposed framework. It also provides the links to the original datasets and the code.</p>
<section id="context" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="context"><span class="header-section-number">1.1</span> Context</h2>
<p>Forests are a crucial part of the global ecosystem, both environmentally and economically. They cover a third of the land area, contain over 80% of terrestrial biodiversity, and somewhere around one-third of humanity depends on forests and forest products for their livelihoods <span class="citation" data-cites="aertsForestRestorationBiodiversity2011 StateWorldsForests2020">(<a href="99_references.html#ref-aertsForestRestorationBiodiversity2011" role="doc-biblioref">Aerts and Honnay 2011</a>; <a href="99_references.html#ref-StateWorldsForests2020" role="doc-biblioref"><em>The <span>State</span> of the <span>World</span>’s <span>Forests</span></em> 2020</a>)</span>. Forests are an essential renewable natural resource and a huge, dynamic part of the global carbon cycle. Responsible management of forests allows using the resources efficiently and sustainably, preserving the biodiversity, and regulating atmospheric <span class="math inline">\(CO_2\)</span>, which is becoming especially important as the anthropogenic climate change is ongoing and accelerating <span class="citation" data-cites="faheyForestCarbonStorage2010 forsterIndicatorsGlobalClimate2024">(<a href="99_references.html#ref-faheyForestCarbonStorage2010" role="doc-biblioref">Fahey et al. 2010</a>; <a href="99_references.html#ref-forsterIndicatorsGlobalClimate2024" role="doc-biblioref">Forster et al. 2024</a>)</span>. This drives the need for accurate, detailed, up-to-date information about various forest attributes such as distributions of tree species, average heights and ages of trees, estimates of trunk diameter, timber volume, and above ground biomass, and others.</p>
<p>The traditional manual forest inventories that rely on people going out into the forest to count and measure trees are extremely labor-intensive and time-consuming, which makes them infeasible to cover extensive areas with sufficient detail, speed, and frequency <span class="citation" data-cites="burleyEncyclopediaForestSciences2004">(<a href="99_references.html#ref-burleyEncyclopediaForestSciences2004" role="doc-biblioref">Burley, Youngquist, and Evans 2004</a>)</span>. This is especially relevant in countries where massive areas are covered by forests, such as Russia, Brazil, Canada, USA, and China, which are the top five countries for forest area according to <span class="citation" data-cites="GlobalForestResources2020"><em>Global <span>Forest Resources Assessment</span></em> (<a href="99_references.html#ref-GlobalForestResources2020" role="doc-biblioref">2020</a>)</span>. For that reason, various remote sensing techniques are widely used to extend and extrapolate the traditional forest inventories. All sorts of data, from satellite and aerial imagery to very detailed terrestrial LiDAR surveys, are used in all sorts of applications that require mapping forest attributes. Some such applications are mentioned in the next chapter dedicated to reviewing the literature.</p>
<p>Many national space agencies even provide open access to satellite data that can be used for mapping forests. European Space Agency offers free and open access<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> to the Sentinel missions, including C-band SAR data from Sentinel-1 and medium-resolution multispectral data from Sentinel-2, both with global coverage. They also have an upcoming P-band SAR mission called BIOMASS, designed specifically to study global forest biomass and carbon cycles <span class="citation" data-cites="queganEuropeanSpaceAgency2019">(<a href="99_references.html#ref-queganEuropeanSpaceAgency2019" role="doc-biblioref">Quegan et al. 2019</a>)</span>, which further indicates the growing importance and interest in the topic of forest mapping. NASA provides free access to an abundance of satellite data through its Earthdata platform, Landsat mission with the Operation Land Imager (OLI) instrument and Terra mission with Moderate Resolution Imaging Spectroradiometer (MODIS) instrument being the most relevant for forest mapping applications. The Indian Space Research Organisation, Brazilian National Institute for Space Research, National Space Research and Development Agency of Nigeria all offer free satellite data that can be used for this purpose.</p>
<p>The open satellite data is an essential tool for wide-area studies, but it usually has coarse resolution, which limits the achievable accuracy and level of detail. It also offers no ability to control the observation parameters, as they are fixed by the instrument configuration and orbit parameters, both of which are outside the data consumer control. Higher resolution data with a limited ability to control the acquisition parameters is available commercially, but the prices are steep. Aerial observations with sensors mounted on planes or helicopters are both more controllable and cheaper alternatives, although still expensive and sill limited in the flexibility of the control of acquisition parameters. A much more affordable and controllable alternative is UAV-based observation. It allows for fine-grained control and on the fly adjustment of many important parameters such as flight height, flight path overlap, combination of used sensors, and so on.</p>
<p>The most common way to use UAV remote sensing, be it LiDAR, multispectral, hyperspectral, or other data modalities, for mapping forest attributes in industry is what is known in the LiDAR community as the area-based approach, described in detail in <a href="02_literature_review.html#sec-area-based-approach" class="quarto-xref"><span>Section 2.3</span></a>. It is based on extrapolating measurements from ground plots made in traditional inventories by aggregating remote sensing data to the grid with cell area of a ground plot, which results in coarse resolution maps. It is easy to use, but its results are often not detailed enough when working on smaller scales. However, modern sensors and processing techniques allow not aggregating at all and instead working on the level of individual trees, which is as detailed as it can possibly get, allowing for any level of aggregation for downstream tasks. This requires robust algorithms that allow detecting individual trees in dense multimodal data. This is relatively<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> easy in urban environments, manually planted and managed forest stands, or forests that are either sparse or predominantly coniferous, where the structure of the canopy is easy to interpret. In some such environments state-of-the-art results can be achieved by simple local maxima detection algorithms, that rely on the assumption that a tree can be detected by finding peaks on of canopies because they correspond to tree tops. Forest that are mixed and dense, which are a huge part of forests in countries mentioned earlier, are much harder to work with and are a very active area of research for developing methods of detection of individual trees. The canopies in such forests are very complex, especially because the top of the crowns of deciduous tree species often don’t have a single pronounced height maximum, and crowns of nearby trees often overlap.</p>
<p>The framework described in this thesis focuses on fusion of two remote sensing data sources, UAV LiDAR point clouds and UAV RGB orthophotos, to detect individual trees in dense mixed forests and predict required attributes for each tree individually, producing the most detailed maps possible. The choice of data sources is driven by their complementary nature, which I believe is key for semantically parsing such complex environments. LiDAR is an active sensor, which means it does not depend on external conditions such as lightning. Cloud and terrain shadows, incidence angles, and weather conditions do not affect LiDAR surveys. Moreover, LiDAR provides 3D vertical structural information about the forest, as laser pulses penetrate the canopy and reach both the undergrowth and the ground. This structural information is essential for understanding complex environments like dense forests. High-resolution RGB imagery does depend on the lighting, but is still an invaluable tool, as it offers detailed data with fixed resolution, continuous coverage of surfaces, unlike the discrete representation of laser scanning, and captures many fine details and textures. It can also benefit from a huge variety of well-established tools and processing techniques from the field of computer vision. Neither of these data sources on their own is enough to reliably and with sufficient robustness separate individual trees in dense mixed forests, and the key to success lies in their fusion.</p>
</section>
<section id="research-question-and-hypothesis" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="research-question-and-hypothesis"><span class="header-section-number">1.2</span> Research question and hypothesis</h2>
<p>The main research question could be formulated as follows: “How to minimize effort and cost required for detailed inventories of dense mixed forests without losing accuracy?” The main hypothesis is then: “An accurate and detailed inventory with minimal effort and cost can be achieved through fusion of UAV LiDAR and RGB data using machine learning”. The cost reduction is self-explanatory and is addressed in the previous subsection during a discussion of the platform of choice. The effort reduction comes mainly from minimizing the amount of field inventory data required. An ideal method is a method that doesn’t require any field inventory data at all except for validation and quality assessment.</p>
</section>
<section id="overview-of-the-framework" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="overview-of-the-framework"><span class="header-section-number">1.3</span> Overview of the framework</h2>
<p>The proposed framework described in this thesis consist of a neural-network based tree segmentation in UAV LiDAR point clouds enhanced with RGB orthophoto-based features and processing the segments with a collection of specialized classic machine learning models that predict the parameters of interest for each detected tree. The tree segmentation model is trained on synthetic forest patches constructed from a dataset of point clouds of individual trees extracted manually from a large UAV LiDAR survey, heavily relying on augmentations to make the synthetic forest closer to real forest. The parameter prediction classification and regression models are trained on the same dataset of individual trees using a collection of widely used manual point cloud features. <a href="#fig-framework-apply" class="quarto-xref">Figure&nbsp;<span>1.1</span></a> is a schematic representation of the framework, showing the required inputs in red, processing steps in yellow, and artifacts in cyan. The field inventory is phased out, but it is still required, as application of any framework requires quality assessment and validation.</p>
<div id="fig-framework-apply" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-framework-apply-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="../images/framework_application_schematic.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure&nbsp;1.1: The schematic representation of the framework in the application stage."><img src="../images/framework_application_schematic.jpg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-framework-apply-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1.1: The schematic representation of the framework in the application stage.
</figcaption>
</figure>
</div>
<p><a href="#fig-framework-prepare" class="quarto-xref">Figure&nbsp;<span>1.2</span></a> is a schematic of the preparation step for the framework. Each individual node is described in detail in <a href="03_materials_and_methods.html" class="quarto-xref"><span>Chapter 3</span></a>.</p>
<div id="fig-framework-prepare" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-framework-prepare-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="../images/framework_preparation_schematic.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;1.2: The schematic representation of the framework in the preparation stage."><img src="../images/framework_preparation_schematic.jpg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-framework-prepare-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1.2: The schematic representation of the framework in the preparation stage.
</figcaption>
</figure>
</div>
</section>
<section id="thesis-structure" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="thesis-structure"><span class="header-section-number">1.4</span> Thesis structure</h2>
<p>The thesis consists of 5 chapters. This section briefly describes the contents and aims of each one.</p>
<p><a href="#sec-introduction" class="quarto-xref"><span>Chapter 1</span></a> aims to give a general introduction to the research project and put it into a wide scientific and societal context. It defines the main research question and the hypothesis, and gives a high-level overview of the proposed framework. It also provides the links to the original datasets and the code.</p>
<p><a href="02_literature_review.html" class="quarto-xref"><span>Chapter 2</span></a> aims to give an overview of the scientific literature on topics most relevant to the project. Its main goals are to provide the reader with context for the research described in the thesis, provide references for in-depth materials on topics that are out of scope of this work, and to highlight the research gap that the work tries to address.</p>
<p><a href="03_materials_and_methods.html" class="quarto-xref"><span>Chapter 3</span></a> describes in detail the datasets, methods and methodological choices used in the proposed framework. Its aim it to make the work reproducible and to explain the methodological choices made.</p>
<p><a href="04_results.html" class="quarto-xref"><span>Chapter 4</span></a> describes the results of each stage of the framework preparation and the validation approach used to verify its applicability and effectiveness on realistic data.</p>
<p><a href="05_conclusion.html" class="quarto-xref"><span>Chapter 5</span></a> offers a brief summary of the thesis as a whole, potential perspectives for further improvement of the proposed framework, and some concluding thoughts.</p>
</section>
<section id="data-and-code-availability" class="level2" data-number="1.5">
<h2 data-number="1.5" class="anchored" data-anchor-id="data-and-code-availability"><span class="header-section-number">1.5</span> Data and code availability</h2>
<p>Original datasets described in the thesis are openly available on Kaggle (Lysva field survey <a href="https://www.kaggle.com/datasets/sentinel3734/tree-detection-lidar-rgb">here</a> and individual tree point clouds <a href="https://www.kaggle.com/datasets/sentinel3734/uav-point-clouds-of-individual-trees">here</a>). All the code used for the project is available on GitHub at <a href="https://github.com/iod-ine/phd">iod-ine/phd</a>. The thesis document was developed using Quarto <span class="citation" data-cites="Allaire_Quarto_2024">(<a href="99_references.html#ref-Allaire_Quarto_2024" role="doc-biblioref">Allaire et al. 2024</a>)</span> using the literate programming approach <span class="citation" data-cites="knuth84">(<a href="99_references.html#ref-knuth84" role="doc-biblioref">Knuth 1984</a>)</span>, and a link to an HTML version hosted through GitHub Pages is available in the repository. The deep learning part is implemented using PyTorch <span class="citation" data-cites="Ansel_PyTorch_2_Faster_2024">(<a href="99_references.html#ref-Ansel_PyTorch_2_Faster_2024" role="doc-biblioref">Ansel et al. 2024</a>)</span>, PyTorch Geometric <span class="citation" data-cites="Fey_Fast_Graph_Representation_2019">(<a href="99_references.html#ref-Fey_Fast_Graph_Representation_2019" role="doc-biblioref">Fey and Lenssen 2019</a>)</span>, and PyTorch Lightning <span class="citation" data-cites="Falcon_PyTorch_Lightning_2019">(<a href="99_references.html#ref-Falcon_PyTorch_Lightning_2019" role="doc-biblioref">Falcon and The PyTorch Lightning team 2019</a>)</span>, with experiment tracking using MLflow. Classic machine learning models implementations are from scikit-learn <span class="citation" data-cites="scikit-learn">(<a href="99_references.html#ref-scikit-learn" role="doc-biblioref">Pedregosa et al. 2011</a>)</span>. NumPy <span class="citation" data-cites="2020NumPy-Array">(<a href="99_references.html#ref-2020NumPy-Array" role="doc-biblioref">Harris et al. 2020</a>)</span>, SciPy <span class="citation" data-cites="2020SciPy-NMeth">(<a href="99_references.html#ref-2020SciPy-NMeth" role="doc-biblioref">Virtanen et al. 2020</a>)</span>, pandas <span class="citation" data-cites="The_pandas_development_team_pandas-dev_pandas_Pandas">(<a href="99_references.html#ref-The_pandas_development_team_pandas-dev_pandas_Pandas" role="doc-biblioref">The pandas development team, n.d.</a>)</span>, scikit-image <span class="citation" data-cites="van_der_Walt_scikit-image_image_processing_2014">(<a href="99_references.html#ref-van_der_Walt_scikit-image_image_processing_2014" role="doc-biblioref">van der Walt et al. 2014</a>)</span> libraries are used for processing the data. ratserio <span class="citation" data-cites="gillies_2019">(<a href="99_references.html#ref-gillies_2019" role="doc-biblioref">Gillies et al. 2013/</a>)</span>, geopandas, laspy, lazrs libraries are used for working with geospatial data formats. matplotlib <span class="citation" data-cites="Hunter_Matplotlib_A_2D_2007">(<a href="99_references.html#ref-Hunter_Matplotlib_A_2D_2007" role="doc-biblioref">Hunter 2007</a>)</span> and seaborn <span class="citation" data-cites="waskomSeabornStatisticalData2021">(<a href="99_references.html#ref-waskomSeabornStatisticalData2021" role="doc-biblioref">Waskom 2021</a>)</span> libraries are used for visualization.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-aertsForestRestorationBiodiversity2011" class="csl-entry" role="listitem">
Aerts, Raf, and Olivier Honnay. 2011. <span>“Forest Restoration, Biodiversity and Ecosystem Functioning.”</span> <em>BMC Ecology</em> 11 (1): 29. <a href="https://doi.org/10.1186/1472-6785-11-29">https://doi.org/10.1186/1472-6785-11-29</a>.
</div>
<div id="ref-Allaire_Quarto_2024" class="csl-entry" role="listitem">
Allaire, J. J., Charles Teague, Carlos Scheidegger, Yihui Xie, and Christophe Dervieux. 2024. <span>“Quarto.”</span> <a href="https://doi.org/10.5281/zenodo.5960048">https://doi.org/10.5281/zenodo.5960048</a>.
</div>
<div id="ref-Ansel_PyTorch_2_Faster_2024" class="csl-entry" role="listitem">
Ansel, Jason, Edward Yang, Horace He, Natalia Gimelshein, Animesh Jain, Michael Voznesensky, Bin Bao, et al. 2024. <span>“<span class="nocase">PyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode Transformation and Graph Compilation</span>.”</span> In <em>29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2 (ASPLOS ’24)</em>. ACM. <a href="https://doi.org/10.1145/3620665.3640366">https://doi.org/10.1145/3620665.3640366</a>.
</div>
<div id="ref-burleyEncyclopediaForestSciences2004" class="csl-entry" role="listitem">
Burley, Jeffery, John Youngquist, and Julian Evans, eds. 2004. <em>Encyclopedia of Forest Sciences</em>. 1st ed. Oxford: Elsevier.
</div>
<div id="ref-faheyForestCarbonStorage2010" class="csl-entry" role="listitem">
Fahey, Timothy J, Peter B Woodbury, John J Battles, Christine L Goodale, Steven P Hamburg, Scott V Ollinger, and Christopher W Woodall. 2010. <span>“Forest Carbon Storage: Ecology, Management, and Policy.”</span> <em>Frontiers in Ecology and the Environment</em> 8 (5): 245–52. <a href="https://doi.org/10.1890/080169">https://doi.org/10.1890/080169</a>.
</div>
<div id="ref-Falcon_PyTorch_Lightning_2019" class="csl-entry" role="listitem">
Falcon, William, and The PyTorch Lightning team. 2019. <span>“<span>PyTorch Lightning</span>.”</span> <a href="https://doi.org/10.5281/zenodo.3828935">https://doi.org/10.5281/zenodo.3828935</a>.
</div>
<div id="ref-Fey_Fast_Graph_Representation_2019" class="csl-entry" role="listitem">
Fey, Matthias, and Jan Eric Lenssen. 2019. <span>“<span class="nocase">Fast Graph Representation Learning with PyTorch Geometric</span>.”</span> <a href="https://github.com/pyg-team/pytorch_geometric">https://github.com/pyg-team/pytorch_geometric</a>.
</div>
<div id="ref-forsterIndicatorsGlobalClimate2024" class="csl-entry" role="listitem">
Forster, Piers M., Chris Smith, Tristram Walsh, William F. Lamb, Robin Lamboll, Bradley Hall, Mathias Hauser, et al. 2024. <span>“Indicators of <span>Global Climate Change</span> 2023: Annual Update of Key Indicators of the State of the Climate System and Human Influence.”</span> <em>Earth System Science Data</em> 16 (6): 2625–58. <a href="https://doi.org/10.5194/essd-16-2625-2024">https://doi.org/10.5194/essd-16-2625-2024</a>.
</div>
<div id="ref-gillies_2019" class="csl-entry" role="listitem">
Gillies, Sean et al. 2013/. <span>“Rasterio: Geospatial Raster <span>I</span>/<span>O</span> for <span>Python</span> Programmers.”</span> Mapbox. <a href="https://github.com/rasterio/rasterio">https://github.com/rasterio/rasterio</a>.
</div>
<div id="ref-GlobalForestResources2020" class="csl-entry" role="listitem">
<em>Global <span>Forest Resources Assessment</span></em>. 2020. FAO. <a href="https://doi.org/10.4060/ca9825en">https://doi.org/10.4060/ca9825en</a>.
</div>
<div id="ref-2020NumPy-Array" class="csl-entry" role="listitem">
Harris, Charles R., K. Jarrod Millman, Stéfan J van der Walt, Ralf Gommers, Pauli Virtanen, David Cournapeau, Eric Wieser, et al. 2020. <span>“Array Programming with <span>NumPy</span>.”</span> <em>Nature</em> 585: 357–62. <a href="https://doi.org/10.1038/s41586-020-2649-2">https://doi.org/10.1038/s41586-020-2649-2</a>.
</div>
<div id="ref-Hunter_Matplotlib_A_2D_2007" class="csl-entry" role="listitem">
Hunter, John D. 2007. <span>“Matplotlib: <span>A 2D</span> Graphics Environment.”</span> <em>Computing in Science &amp; Engineering</em> 9 (3): 90–95. <a href="https://doi.org/10.1109/MCSE.2007.55">https://doi.org/10.1109/MCSE.2007.55</a>.
</div>
<div id="ref-knuth84" class="csl-entry" role="listitem">
Knuth, Donald E. 1984. <span>“Literate Programming.”</span> <em>Comput. J.</em> 27 (2): 97–111. <a href="https://doi.org/10.1093/comjnl/27.2.97">https://doi.org/10.1093/comjnl/27.2.97</a>.
</div>
<div id="ref-scikit-learn" class="csl-entry" role="listitem">
Pedregosa, F., G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, et al. 2011. <span>“Scikit-Learn: Machine Learning in <span>P</span>ython.”</span> <em>Journal of Machine Learning Research</em> 12: 2825–30.
</div>
<div id="ref-queganEuropeanSpaceAgency2019" class="csl-entry" role="listitem">
Quegan, Shaun, Thuy Le Toan, Jerome Chave, Jorgen Dall, Jean-François Exbrayat, Dinh Ho Tong Minh, Mark Lomas, et al. 2019. <span>“The <span>European Space Agency BIOMASS</span> Mission: <span>Measuring</span> Forest Above-Ground Biomass from Space.”</span> <em>Remote Sensing of Environment</em> 227 (June): 44–60. <a href="https://doi.org/10.1016/j.rse.2019.03.032">https://doi.org/10.1016/j.rse.2019.03.032</a>.
</div>
<div id="ref-The_pandas_development_team_pandas-dev_pandas_Pandas" class="csl-entry" role="listitem">
The pandas development team. n.d. <span>“Pandas-Dev/Pandas: <span>Pandas</span>.”</span> <a href="https://doi.org/10.5281/zenodo.3509134">https://doi.org/10.5281/zenodo.3509134</a>.
</div>
<div id="ref-StateWorldsForests2020" class="csl-entry" role="listitem">
<em>The <span>State</span> of the <span>World</span>’s <span>Forests</span></em>. 2020. <span>FAO and UNEP</span>. <a href="https://doi.org/10.4060/ca8642en">https://doi.org/10.4060/ca8642en</a>.
</div>
<div id="ref-van_der_Walt_scikit-image_image_processing_2014" class="csl-entry" role="listitem">
van der Walt, Stéfan J., Johannes L. Schönberger, Juan Nunez-Iglesias, François Boulogne, Joshua D. Warner, Neil Yager, Emmanuelle Gouillart, Tony Yu, and the scikit-image contributors. 2014. <span>“Scikit-Image: Image Processing in <span>Python</span>.”</span> <em>PeerJ</em> 2 (June): e453. <a href="https://doi.org/10.7717/peerj.453">https://doi.org/10.7717/peerj.453</a>.
</div>
<div id="ref-2020SciPy-NMeth" class="csl-entry" role="listitem">
Virtanen, Pauli, Ralf Gommers, Travis E. Oliphant, Matt Haberland, Tyler Reddy, David Cournapeau, Evgeni Burovski, et al. 2020. <span>“<span>SciPy</span> 1.0: <span>Fundamental Algorithms</span> for <span>Scientific Computing</span> in <span>Python</span>.”</span> <em>Nature Methods</em> 17: 261–72. <a href="https://doi.org/10.1038/s41592-019-0686-2">https://doi.org/10.1038/s41592-019-0686-2</a>.
</div>
<div id="ref-waskomSeabornStatisticalData2021" class="csl-entry" role="listitem">
Waskom, Michael. 2021. <span>“Seaborn: Statistical Data Visualization.”</span> <em>Journal of Open Source Software</em> 6 (60): 3021. <a href="https://doi.org/10.21105/joss.03021">https://doi.org/10.21105/joss.03021</a>.
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Although the access is not open for everyone equally, as I have observed silent bans of the accounts connecting from Russian IP-addresses without any response to support inquires.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>The word relatively does a lot of heavy lifting here, as the problem is by no means easy on its own and takes a lot of effort from many researchers to continue to make progress on.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../index.html" class="pagination-link" aria-label="Acknowledgments <span style=&quot;visibility: hidden&quot;>🌹</span>">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Acknowledgments <span style="visibility: hidden">🌹</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapters/02_literature_review.html" class="pagination-link" aria-label="Literature review">
        <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Literature review</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/iod-ine/thesis/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li><li><a href="https://github.com/iod-ine/thesis/blob/main/chapters/01_introduction.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li></ul></div></div></div></footer><script>var lightboxQuarto = GLightbox({"loop":false,"openEffect":"zoom","closeEffect":"zoom","selector":".lightbox","descPosition":"bottom"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>