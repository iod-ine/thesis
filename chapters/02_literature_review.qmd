# Literature review

This chapter provides an overview of the current state of literature on a variety of related subjects.

### Terrestrial LiDAR

Terrestrial LiDAR surveys usually provide very dense and detailed point clouds.
Most importantly for the task of localizing individual trees, terrestrial measurements always capture the trunks of the trees clearly.
Tree trunks are very useful for tree detection and segmentation, and there are many algorithms that use bottom-to-top approaches that trace the trunks into the canopies.

[@nurunnabiDevelopmentPreciseTree2024] offers a compelling example of how such detailed data can be used to provide very detailed analyses on tree level.
The authors report high accuracies on the task of segmenting the point clouds

### Fusion of data
[@balestraLiDARDataFusion2024] offers a review of 151 publications concerning fusion of LiDAR data with other remote sensing data.
The authors report that in most cases fusion improves the results.

## Area-based approach

The most common way to use LiDAR for mapping forest attributes is the area-based approach [@whiteABAGuide2013].
@fig-aba-schema shows its schematic representation.
It consists of a LiDAR survey covering the whole area of interest and a manual forest inventory providing ground truth data for fitting statistical models and validating the results.
The inventory usually consists of many circular ground plots with every tree within counted and attributes of interest either directly measured or calculated and averaged.
The point cloud is clipped by the extents of the ground plots, and for each plot it is reduced to a collection of manually selected metrics.
The metrics usually include descriptions of the height distribution of the points, but often reflection intensities and other sensor-provided information is used as well, such as the return number, the number of returns, etc. (a brief discussion on the use of intensity-based features can be found in @sec-intensity-as-a-feature).
In general, any summary statistic that can be derived from a collection of points can be used, including features mentioned in @sec-classic-machine-learning.
These metrics are then used as input features for fitting regression and classification models to predict the forest attributes measured on the corresponding plots.
The same metrics are calculated for the entire area of interest, using a grid with a cell size similar in area to the area of a single ground plot.
The models are then applied to the grid, generating an extrapolation of the required attributes.

::: {#fig-aba-schema}
![](../images/aba_schematic.jpg)

Area-based approach schematic. Figure from [@whiteABAGuide2013]
:::

Area-based approach is extensively used both in research and in industry because it provides many advantages.
<!--TODO: Add citations for ABA.-->
It is relatively easy to implement.
In fact, basic familiarity with the R programming language is enough to create your own area-based approach pipelines since a full, scalable implementation exists in the `lidR` package 
[@rousselLidRPackage2020].
It is also straightforward to extend with other data sources such as satellite or aerial images, and it works even with sparse data: for successful plot and stand level modeling point densities as low as 0.5 points per square meter have been reported to be enough [@treitzLiDARSamplingDensity2012; @jakubowskiTradeoffsLidarPulse2013].
Still, it requires a lot of field inventory data to work, since every ground plot becomes a single example for the models.
The models that can be used are also relatively simple, because of how expensive the data collection is.
Data-hungry approaches like neural networks usually don't have enough data to train.
The results are also very coarse â€“ predicted on a grid with the size defined by the area of a plot (a common plot shape is a circle with 9-meter radius, which is approximately equivalent to a square grid cell with 16-meter side).
This is why they are usually further aggregated to stand level.

## Classic machine learning on point clouds {#sec-classic-machine-learning}

## Deep learning on point clouds {#sec-deep-learning}

PointNet [@qiPointNet2017] and PointNet++ [@qiPointNetPlusPlus2017]

::: {#fig-pointnet-architecture}
![](../images/pointnet_architecture.jpg)

PointNet architecture. Figure from [@qiPointNet2017]
:::

::: {#fig-pointnet2-architecture}
![](../images/pointnet2_architecture.jpg)

PointNet++ architecture. Figure from [@qiPointNetPlusPlus2017]
:::
