# Introduction {#sec-introduction}

Forests are a crucial part of the global ecosystem, both environmentally and economically.
They cover a third of the land area, contain over 80% of terrestrial biodiversity, and somewhere around one-third of humanity depends on forests and forest products for their livelihoods [@aertsForestRestorationBiodiversity2011; @StateWorldsForests2020].
Forests are an essential renewable natural resource and a huge, dynamic part of the global carbon cycle.
Responsible management of forests allows using the resources efficiently and sustainably, preserving the biodiversity, and regulating atmospheric $CO_2$, which is becoming especially important as the anthropogenic climate change is ongoing and accelerating [@faheyForestCarbonStorage2010; @forsterIndicatorsGlobalClimate2024].
This drives the need for accurate, detailed, up-to-date information about various forest attributes such as distributions of species, heights, ages of trees, timber volume and above ground biomass estimates, and others.

The traditional manual forest inventories are extremely labor-intensive and time-consuming, which makes them infeasible to cover extensive areas with sufficient detail, speed, and frequency [@burleyEncyclopediaForestSciences2004].
Various remote sensing techniques are used to extend and interpolate manual inventories 

Significantly reduce the required effort, especially in the form of the amount of field inventory data required.
Ideally, a method that doesn't require any field data at all, only for validation and quality assessment.
Match or exceed the accuracy of the area-based approach.

There is a huge variety of remote sensing data sources that have been successfully used to solve various problems in forestry applications.

Starting from the satellite observations ...
There are even many free data sources such as Sentinels (some studies of using S1 and S2, maybe even GEDI).

Higher resolution data is however only available for money, and it isn't cheap.

UAV measurements offer a good balance between the affordability, required effort, and quality of the data.

## Thesis structure

The thesis consists of 5 chapters.
This section briefly describes the contents and aims of each one.

@sec-introduction aims to give a general introduction to the research project and put it into wide scientific and societal context.
It defines the main research question and the hypothesis, and gives a high-level overview of the proposed framework.
It also provides the links to the original datasets and the code.

@sec-literature-review gives an overview of the scientific literature on topics most relevant to the project.
Its main goals are to provide the reader with context for the research described in the thesis, provide references for in-depth materials on topics that are out of scope of this work, and to highlight the research gap that the work tries to address.

@sec-materials-and-methods describes in detail the datasets, methods and methodological choices used in the proposed framework.
It's aim it to make the work reproducible.

@sec-results describes the results and the validation approach used to verify the framework.

@sec-conclusion offers concluding thoughts and potential perspectives for improvement of the proposed framework.

## Data and code availability

Original datasets described in the thesis are openly available on Kaggle at [sentinel3734/tree-detection-lidar-rgb](https://www.kaggle.com/datasets/sentinel3734/tree-detection-lidar-rgb) and [sentinel3734/uav-point-clouds-of-individual-trees](https://www.kaggle.com/datasets/sentinel3734/uav-point-clouds-of-individual-trees).
All the code used for the project is available on GitHub at [iod-ine/phd](https://github.com/iod-ine/phd).
The thesis document was developed using Quarto [@Allaire_Quarto_2024] using the literate programming approach [@knuth84], and a link to an HTML version hosted through GitHub Pages is available in the repository.
The deep learning part is implemented using PyTorch [@Ansel_PyTorch_2_Faster_2024], PyTorch Geometric [@Fey_Fast_Graph_Representation_2019], and PyTorch Lightning [@Falcon_PyTorch_Lightning_2019].
Classic machine learning models implementations are from scikit-learn [@scikit-learn].
NumPy [@2020NumPy-Array], SciPy [@2020SciPy-NMeth], pandas [@The_pandas_development_team_pandas-dev_pandas_Pandas], scikit-image [@van_der_Walt_scikit-image_image_processing_2014] libraries are used for processing the data.
ratserio [@gillies_2019], geopandas, laspy, lazrs libraries are used for working with geospatial data formats.
matplotlib [@Hunter_Matplotlib_A_2D_2007] and seaborn [@waskomSeabornStatisticalData2021] libraries are used for visualization.
