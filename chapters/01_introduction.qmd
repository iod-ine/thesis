# Introduction

Forests are a crucial part of the global ecosystem, both environmentally and economically.
They cover a third of the land area, contain over 80% of terrestrial biodiversity, and somewhere around one-third of humanity depends on forests and forest products for their livelihoods [@aertsForestRestorationBiodiversity2011; @StateWorldsForests2020].
Forests are an essential renewable natural resource and a huge, dynamic part of the global carbon cycle.
Responsible management of forests allows using the resources efficiently and sustainably, preserving the biodiversity, and regulating atmospheric $CO_2$, which is becoming especially important as the anthropogenic climate change is ongoing and accelerating [@faheyForestCarbonStorage2010; @forsterIndicatorsGlobalClimate2024].
This drives the need for accurate, detailed, up-to-date information about various forest attributes such as distributions of species, heights, ages of trees, timber volume and above ground biomass estimates, and others.

The traditional manual forest inventories are extremely labor-intensive and time-consuming, which makes them infeasible to cover extensive areas with sufficient detail, speed, and frequency [@burleyEncyclopediaForestSciences2004].
Various remote sensing techniques are used to extend and interpolate manual inventories 

Significantly reduce the required effort, especially in the form of the amount of field inventory data required.
Ideally, a method that doesn't require any field data at all, only for validation and quality assessment.
Match or exceed the accuracy of the area-based approach.

There is a huge variety of remote sensing data sources that have been successfully used to solve various problems in forestry applications.

Starting from the satellite observations ...
There are even many free data sources such as Sentinels (some studies of using S1 and S2, maybe even GEDI).

Higher resolution data is however only available for money, and it isn't cheap.

UAV measurements offer a good balance between the affordability, required effort, and quality of the data.

Original datasets described in the thesis are openly available on Kaggle.
All the code used for the project is on GitHub at [iod-ine/phd](https://github.com/iod-ine/phd).
The deep learning part is implemented using PyTorch [@Ansel_PyTorch_2_Faster_2024], PyTorch Geometric [@Fey_Fast_Graph_Representation_2019], and PyTorch Lightning [@Falcon_PyTorch_Lightning_2019].
Classic machine learning models implementations are from scikit-learn [@scikit-learn].
NumPy [@2020NumPy-Array], pandas [@The_pandas_development_team_pandas-dev_pandas_Pandas], scikit-image [@van_der_Walt_scikit-image_image_processing_2014] libraries are used for processing the data.
ratserio [@gillies_2019], geopandas, laspy, lazrs libraries are used for working with geospatial data formats.
matplotlib [@Hunter_Matplotlib_A_2D_2007] and seaborn [@waskomSeabornStatisticalData2021] libraries are used for visualization.
